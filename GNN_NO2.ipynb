{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ditsuhi/Graph_Neural_Networks_A3T_GCN/blob/main/A3T_GCN_LSTM_GRU_NO2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I1ZeoGyGB4J"
      },
      "outputs": [],
      "source": [
        "#install pytorch and all related libraries\n",
        "#it will take some time\n",
        "\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch-geometric-temporal\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import all required libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from tensorflow import keras\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "from torch_geometric_temporal.signal import StaticGraphTemporalSignalBatch, StaticGraphTemporalSignal\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric_temporal.nn.recurrent import A3TGCN\n",
        "from keras.layers import   GRU,   Dense \n",
        "import scipy.stats\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zHeUOEsQuUoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "PCbQqRRgDLtN",
        "outputId": "5b3abf6c-e4a2-4654-deb4-898d7631db94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          5         47        72        78        88        92        113  \\\n",
              "5    0.000000  0.110356  0.236273  0.143935  0.181212  0.164228  0.112551   \n",
              "47   0.110356  0.000000  0.109257  0.267139  0.095718  0.144390  0.208583   \n",
              "72   0.236273  0.109257  0.000000  0.174832  0.645102  0.325035  0.148464   \n",
              "78   0.143935  0.267139  0.174832  0.000000  0.145813  0.313177  0.442175   \n",
              "88   0.181212  0.095718  0.645102  0.145813  0.000000  0.260419  0.133522   \n",
              "92   0.164228  0.144390  0.325035  0.313177  0.260419  0.000000  0.271064   \n",
              "113  0.112551  0.208583  0.148464  0.442175  0.133522  0.271064  0.000000   \n",
              "126  0.126298  0.132625  0.222798  0.254499  0.211733  0.540075  0.308841   \n",
              "138  0.117328  0.079494  0.221339  0.113106  0.330050  0.176855  0.114254   \n",
              "141  0.117353  0.097987  0.229932  0.153721  0.275207  0.278847  0.168040   \n",
              "142  0.124251  0.107809  0.248793  0.179284  0.274416  0.367075  0.197347   \n",
              "143  0.115321  0.124468  0.196040  0.220380  0.194237  0.379903  0.286935   \n",
              "177  0.095410  0.100376  0.152651  0.150958  0.163359  0.215033  0.191733   \n",
              "181  0.082770  0.128353  0.109845  0.170751  0.107200  0.162230  0.277714   \n",
              "192  0.091417  0.087746  0.147244  0.126098  0.166278  0.180396  0.149161   \n",
              "195  0.083470  0.096880  0.122364  0.135770  0.128027  0.167196  0.180343   \n",
              "217  0.066397  0.102601  0.082703  0.116351  0.081739  0.109029  0.157361   \n",
              "220  0.058654  0.097302  0.068796  0.097973  0.067254  0.086970  0.122457   \n",
              "228  0.075098  0.082217  0.107523  0.109166  0.115331  0.133413  0.135411   \n",
              "243  0.068696  0.069394  0.096458  0.089090  0.106098  0.109384  0.103990   \n",
              "254  0.054583  0.084349  0.064189  0.086394  0.063360  0.079381  0.105806   \n",
              "281  0.059056  0.071076  0.076388  0.084737  0.079434  0.091725  0.103478   \n",
              "296  0.058305  0.064031  0.076561  0.077548  0.081462  0.087882  0.091317   \n",
              "323  0.050814  0.047170  0.064459  0.056153  0.070607  0.065522  0.060882   \n",
              "\n",
              "          126       138       141  ...       192       195       217  \\\n",
              "5    0.126298  0.117328  0.117353  ...  0.091417  0.083470  0.066397   \n",
              "47   0.132625  0.079494  0.097987  ...  0.087746  0.096880  0.102601   \n",
              "72   0.222798  0.221339  0.229932  ...  0.147244  0.122364  0.082703   \n",
              "78   0.254499  0.113106  0.153721  ...  0.126098  0.135770  0.116351   \n",
              "88   0.211733  0.330050  0.275207  ...  0.166278  0.128027  0.081739   \n",
              "92   0.540075  0.176855  0.278847  ...  0.180396  0.167196  0.109029   \n",
              "113  0.308841  0.114254  0.168040  ...  0.149161  0.180343  0.157361   \n",
              "126  0.000000  0.180816  0.365729  ...  0.247734  0.241840  0.131396   \n",
              "138  0.180816  0.000000  0.331141  ...  0.223056  0.144352  0.083149   \n",
              "141  0.365729  0.331141  0.000000  ...  0.409101  0.234668  0.109792   \n",
              "142  0.545834  0.266708  1.075541  ...  0.339723  0.238133  0.115072   \n",
              "143  1.266551  0.181021  0.391533  ...  0.294498  0.298593  0.141066   \n",
              "177  0.344411  0.187088  0.389015  ...  0.643446  0.589755  0.149415   \n",
              "181  0.215382  0.105748  0.155032  ...  0.172656  0.287938  0.332458   \n",
              "192  0.247734  0.223056  0.409101  ...  0.000000  0.383024  0.126843   \n",
              "195  0.241840  0.144352  0.234668  ...  0.383024  0.000000  0.189541   \n",
              "217  0.131396  0.083149  0.109792  ...  0.126843  0.189541  0.000000   \n",
              "220  0.098479  0.066961  0.083599  ...  0.091766  0.120511  0.328968   \n",
              "228  0.175335  0.139938  0.198333  ...  0.368000  0.543167  0.162218   \n",
              "243  0.133346  0.138718  0.165686  ...  0.274047  0.240868  0.120425   \n",
              "254  0.089911  0.064239  0.078932  ...  0.088265  0.114620  0.280409   \n",
              "281  0.110489  0.090053  0.111642  ...  0.149370  0.201828  0.189488   \n",
              "296  0.104375  0.097515  0.114614  ...  0.159146  0.180192  0.130992   \n",
              "323  0.071900  0.089265  0.085327  ...  0.101223  0.090280  0.067329   \n",
              "\n",
              "          220       228       243       254       281       296       323  \n",
              "5    0.058654  0.075098  0.068696  0.054583  0.059056  0.058305  0.050814  \n",
              "47   0.097302  0.082217  0.069394  0.084349  0.071076  0.064031  0.047170  \n",
              "72   0.068796  0.107523  0.096458  0.064189  0.076388  0.076561  0.064459  \n",
              "78   0.097973  0.109166  0.089090  0.086394  0.084737  0.077548  0.056153  \n",
              "88   0.067254  0.115331  0.106098  0.063360  0.079434  0.081462  0.070607  \n",
              "92   0.086970  0.133413  0.109384  0.079381  0.091725  0.087882  0.065522  \n",
              "113  0.122457  0.135411  0.103990  0.105806  0.103478  0.091317  0.060882  \n",
              "126  0.098479  0.175335  0.133346  0.089911  0.110489  0.104375  0.071900  \n",
              "138  0.066961  0.139938  0.138718  0.064239  0.090053  0.097515  0.089265  \n",
              "141  0.083599  0.198333  0.165686  0.078932  0.111642  0.114614  0.085327  \n",
              "142  0.087317  0.188930  0.151688  0.081598  0.110142  0.109845  0.079752  \n",
              "143  0.102567  0.203267  0.147834  0.094033  0.120828  0.113710  0.075350  \n",
              "177  0.103698  0.350084  0.216424  0.097819  0.152886  0.148460  0.088951  \n",
              "181  0.179845  0.197353  0.134133  0.154318  0.159274  0.125521  0.069535  \n",
              "192  0.091766  0.368000  0.274047  0.088265  0.149370  0.159146  0.101223  \n",
              "195  0.120511  0.543167  0.240868  0.114620  0.201828  0.180192  0.090280  \n",
              "217  0.328968  0.162218  0.120425  0.280409  0.189488  0.130992  0.067329  \n",
              "220  0.000000  0.108908  0.088921  0.618468  0.130787  0.098220  0.056897  \n",
              "228  0.108908  0.000000  0.418550  0.107466  0.251363  0.257507  0.107236  \n",
              "243  0.088921  0.418550  0.000000  0.089666  0.213903  0.323453  0.144101  \n",
              "254  0.618468  0.107466  0.089666  0.000000  0.141058  0.103476  0.058424  \n",
              "281  0.130787  0.251363  0.213903  0.141058  0.000000  0.388382  0.099729  \n",
              "296  0.098220  0.257507  0.323453  0.103476  0.388382  0.000000  0.134183  \n",
              "323  0.056897  0.107236  0.144101  0.058424  0.099729  0.134183  0.000000  \n",
              "\n",
              "[24 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a07d21a1-821d-47d6-8ce2-c74177714848\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>5</th>\n",
              "      <th>47</th>\n",
              "      <th>72</th>\n",
              "      <th>78</th>\n",
              "      <th>88</th>\n",
              "      <th>92</th>\n",
              "      <th>113</th>\n",
              "      <th>126</th>\n",
              "      <th>138</th>\n",
              "      <th>141</th>\n",
              "      <th>...</th>\n",
              "      <th>192</th>\n",
              "      <th>195</th>\n",
              "      <th>217</th>\n",
              "      <th>220</th>\n",
              "      <th>228</th>\n",
              "      <th>243</th>\n",
              "      <th>254</th>\n",
              "      <th>281</th>\n",
              "      <th>296</th>\n",
              "      <th>323</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.110356</td>\n",
              "      <td>0.236273</td>\n",
              "      <td>0.143935</td>\n",
              "      <td>0.181212</td>\n",
              "      <td>0.164228</td>\n",
              "      <td>0.112551</td>\n",
              "      <td>0.126298</td>\n",
              "      <td>0.117328</td>\n",
              "      <td>0.117353</td>\n",
              "      <td>...</td>\n",
              "      <td>0.091417</td>\n",
              "      <td>0.083470</td>\n",
              "      <td>0.066397</td>\n",
              "      <td>0.058654</td>\n",
              "      <td>0.075098</td>\n",
              "      <td>0.068696</td>\n",
              "      <td>0.054583</td>\n",
              "      <td>0.059056</td>\n",
              "      <td>0.058305</td>\n",
              "      <td>0.050814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.110356</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.109257</td>\n",
              "      <td>0.267139</td>\n",
              "      <td>0.095718</td>\n",
              "      <td>0.144390</td>\n",
              "      <td>0.208583</td>\n",
              "      <td>0.132625</td>\n",
              "      <td>0.079494</td>\n",
              "      <td>0.097987</td>\n",
              "      <td>...</td>\n",
              "      <td>0.087746</td>\n",
              "      <td>0.096880</td>\n",
              "      <td>0.102601</td>\n",
              "      <td>0.097302</td>\n",
              "      <td>0.082217</td>\n",
              "      <td>0.069394</td>\n",
              "      <td>0.084349</td>\n",
              "      <td>0.071076</td>\n",
              "      <td>0.064031</td>\n",
              "      <td>0.047170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>0.236273</td>\n",
              "      <td>0.109257</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.174832</td>\n",
              "      <td>0.645102</td>\n",
              "      <td>0.325035</td>\n",
              "      <td>0.148464</td>\n",
              "      <td>0.222798</td>\n",
              "      <td>0.221339</td>\n",
              "      <td>0.229932</td>\n",
              "      <td>...</td>\n",
              "      <td>0.147244</td>\n",
              "      <td>0.122364</td>\n",
              "      <td>0.082703</td>\n",
              "      <td>0.068796</td>\n",
              "      <td>0.107523</td>\n",
              "      <td>0.096458</td>\n",
              "      <td>0.064189</td>\n",
              "      <td>0.076388</td>\n",
              "      <td>0.076561</td>\n",
              "      <td>0.064459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>0.143935</td>\n",
              "      <td>0.267139</td>\n",
              "      <td>0.174832</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.145813</td>\n",
              "      <td>0.313177</td>\n",
              "      <td>0.442175</td>\n",
              "      <td>0.254499</td>\n",
              "      <td>0.113106</td>\n",
              "      <td>0.153721</td>\n",
              "      <td>...</td>\n",
              "      <td>0.126098</td>\n",
              "      <td>0.135770</td>\n",
              "      <td>0.116351</td>\n",
              "      <td>0.097973</td>\n",
              "      <td>0.109166</td>\n",
              "      <td>0.089090</td>\n",
              "      <td>0.086394</td>\n",
              "      <td>0.084737</td>\n",
              "      <td>0.077548</td>\n",
              "      <td>0.056153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>0.181212</td>\n",
              "      <td>0.095718</td>\n",
              "      <td>0.645102</td>\n",
              "      <td>0.145813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.260419</td>\n",
              "      <td>0.133522</td>\n",
              "      <td>0.211733</td>\n",
              "      <td>0.330050</td>\n",
              "      <td>0.275207</td>\n",
              "      <td>...</td>\n",
              "      <td>0.166278</td>\n",
              "      <td>0.128027</td>\n",
              "      <td>0.081739</td>\n",
              "      <td>0.067254</td>\n",
              "      <td>0.115331</td>\n",
              "      <td>0.106098</td>\n",
              "      <td>0.063360</td>\n",
              "      <td>0.079434</td>\n",
              "      <td>0.081462</td>\n",
              "      <td>0.070607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>0.164228</td>\n",
              "      <td>0.144390</td>\n",
              "      <td>0.325035</td>\n",
              "      <td>0.313177</td>\n",
              "      <td>0.260419</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.271064</td>\n",
              "      <td>0.540075</td>\n",
              "      <td>0.176855</td>\n",
              "      <td>0.278847</td>\n",
              "      <td>...</td>\n",
              "      <td>0.180396</td>\n",
              "      <td>0.167196</td>\n",
              "      <td>0.109029</td>\n",
              "      <td>0.086970</td>\n",
              "      <td>0.133413</td>\n",
              "      <td>0.109384</td>\n",
              "      <td>0.079381</td>\n",
              "      <td>0.091725</td>\n",
              "      <td>0.087882</td>\n",
              "      <td>0.065522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>0.112551</td>\n",
              "      <td>0.208583</td>\n",
              "      <td>0.148464</td>\n",
              "      <td>0.442175</td>\n",
              "      <td>0.133522</td>\n",
              "      <td>0.271064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.308841</td>\n",
              "      <td>0.114254</td>\n",
              "      <td>0.168040</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149161</td>\n",
              "      <td>0.180343</td>\n",
              "      <td>0.157361</td>\n",
              "      <td>0.122457</td>\n",
              "      <td>0.135411</td>\n",
              "      <td>0.103990</td>\n",
              "      <td>0.105806</td>\n",
              "      <td>0.103478</td>\n",
              "      <td>0.091317</td>\n",
              "      <td>0.060882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>0.126298</td>\n",
              "      <td>0.132625</td>\n",
              "      <td>0.222798</td>\n",
              "      <td>0.254499</td>\n",
              "      <td>0.211733</td>\n",
              "      <td>0.540075</td>\n",
              "      <td>0.308841</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.180816</td>\n",
              "      <td>0.365729</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247734</td>\n",
              "      <td>0.241840</td>\n",
              "      <td>0.131396</td>\n",
              "      <td>0.098479</td>\n",
              "      <td>0.175335</td>\n",
              "      <td>0.133346</td>\n",
              "      <td>0.089911</td>\n",
              "      <td>0.110489</td>\n",
              "      <td>0.104375</td>\n",
              "      <td>0.071900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>0.117328</td>\n",
              "      <td>0.079494</td>\n",
              "      <td>0.221339</td>\n",
              "      <td>0.113106</td>\n",
              "      <td>0.330050</td>\n",
              "      <td>0.176855</td>\n",
              "      <td>0.114254</td>\n",
              "      <td>0.180816</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.331141</td>\n",
              "      <td>...</td>\n",
              "      <td>0.223056</td>\n",
              "      <td>0.144352</td>\n",
              "      <td>0.083149</td>\n",
              "      <td>0.066961</td>\n",
              "      <td>0.139938</td>\n",
              "      <td>0.138718</td>\n",
              "      <td>0.064239</td>\n",
              "      <td>0.090053</td>\n",
              "      <td>0.097515</td>\n",
              "      <td>0.089265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>0.117353</td>\n",
              "      <td>0.097987</td>\n",
              "      <td>0.229932</td>\n",
              "      <td>0.153721</td>\n",
              "      <td>0.275207</td>\n",
              "      <td>0.278847</td>\n",
              "      <td>0.168040</td>\n",
              "      <td>0.365729</td>\n",
              "      <td>0.331141</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.409101</td>\n",
              "      <td>0.234668</td>\n",
              "      <td>0.109792</td>\n",
              "      <td>0.083599</td>\n",
              "      <td>0.198333</td>\n",
              "      <td>0.165686</td>\n",
              "      <td>0.078932</td>\n",
              "      <td>0.111642</td>\n",
              "      <td>0.114614</td>\n",
              "      <td>0.085327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>0.124251</td>\n",
              "      <td>0.107809</td>\n",
              "      <td>0.248793</td>\n",
              "      <td>0.179284</td>\n",
              "      <td>0.274416</td>\n",
              "      <td>0.367075</td>\n",
              "      <td>0.197347</td>\n",
              "      <td>0.545834</td>\n",
              "      <td>0.266708</td>\n",
              "      <td>1.075541</td>\n",
              "      <td>...</td>\n",
              "      <td>0.339723</td>\n",
              "      <td>0.238133</td>\n",
              "      <td>0.115072</td>\n",
              "      <td>0.087317</td>\n",
              "      <td>0.188930</td>\n",
              "      <td>0.151688</td>\n",
              "      <td>0.081598</td>\n",
              "      <td>0.110142</td>\n",
              "      <td>0.109845</td>\n",
              "      <td>0.079752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>0.115321</td>\n",
              "      <td>0.124468</td>\n",
              "      <td>0.196040</td>\n",
              "      <td>0.220380</td>\n",
              "      <td>0.194237</td>\n",
              "      <td>0.379903</td>\n",
              "      <td>0.286935</td>\n",
              "      <td>1.266551</td>\n",
              "      <td>0.181021</td>\n",
              "      <td>0.391533</td>\n",
              "      <td>...</td>\n",
              "      <td>0.294498</td>\n",
              "      <td>0.298593</td>\n",
              "      <td>0.141066</td>\n",
              "      <td>0.102567</td>\n",
              "      <td>0.203267</td>\n",
              "      <td>0.147834</td>\n",
              "      <td>0.094033</td>\n",
              "      <td>0.120828</td>\n",
              "      <td>0.113710</td>\n",
              "      <td>0.075350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>0.095410</td>\n",
              "      <td>0.100376</td>\n",
              "      <td>0.152651</td>\n",
              "      <td>0.150958</td>\n",
              "      <td>0.163359</td>\n",
              "      <td>0.215033</td>\n",
              "      <td>0.191733</td>\n",
              "      <td>0.344411</td>\n",
              "      <td>0.187088</td>\n",
              "      <td>0.389015</td>\n",
              "      <td>...</td>\n",
              "      <td>0.643446</td>\n",
              "      <td>0.589755</td>\n",
              "      <td>0.149415</td>\n",
              "      <td>0.103698</td>\n",
              "      <td>0.350084</td>\n",
              "      <td>0.216424</td>\n",
              "      <td>0.097819</td>\n",
              "      <td>0.152886</td>\n",
              "      <td>0.148460</td>\n",
              "      <td>0.088951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>0.082770</td>\n",
              "      <td>0.128353</td>\n",
              "      <td>0.109845</td>\n",
              "      <td>0.170751</td>\n",
              "      <td>0.107200</td>\n",
              "      <td>0.162230</td>\n",
              "      <td>0.277714</td>\n",
              "      <td>0.215382</td>\n",
              "      <td>0.105748</td>\n",
              "      <td>0.155032</td>\n",
              "      <td>...</td>\n",
              "      <td>0.172656</td>\n",
              "      <td>0.287938</td>\n",
              "      <td>0.332458</td>\n",
              "      <td>0.179845</td>\n",
              "      <td>0.197353</td>\n",
              "      <td>0.134133</td>\n",
              "      <td>0.154318</td>\n",
              "      <td>0.159274</td>\n",
              "      <td>0.125521</td>\n",
              "      <td>0.069535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>0.091417</td>\n",
              "      <td>0.087746</td>\n",
              "      <td>0.147244</td>\n",
              "      <td>0.126098</td>\n",
              "      <td>0.166278</td>\n",
              "      <td>0.180396</td>\n",
              "      <td>0.149161</td>\n",
              "      <td>0.247734</td>\n",
              "      <td>0.223056</td>\n",
              "      <td>0.409101</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.383024</td>\n",
              "      <td>0.126843</td>\n",
              "      <td>0.091766</td>\n",
              "      <td>0.368000</td>\n",
              "      <td>0.274047</td>\n",
              "      <td>0.088265</td>\n",
              "      <td>0.149370</td>\n",
              "      <td>0.159146</td>\n",
              "      <td>0.101223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0.083470</td>\n",
              "      <td>0.096880</td>\n",
              "      <td>0.122364</td>\n",
              "      <td>0.135770</td>\n",
              "      <td>0.128027</td>\n",
              "      <td>0.167196</td>\n",
              "      <td>0.180343</td>\n",
              "      <td>0.241840</td>\n",
              "      <td>0.144352</td>\n",
              "      <td>0.234668</td>\n",
              "      <td>...</td>\n",
              "      <td>0.383024</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.189541</td>\n",
              "      <td>0.120511</td>\n",
              "      <td>0.543167</td>\n",
              "      <td>0.240868</td>\n",
              "      <td>0.114620</td>\n",
              "      <td>0.201828</td>\n",
              "      <td>0.180192</td>\n",
              "      <td>0.090280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>0.066397</td>\n",
              "      <td>0.102601</td>\n",
              "      <td>0.082703</td>\n",
              "      <td>0.116351</td>\n",
              "      <td>0.081739</td>\n",
              "      <td>0.109029</td>\n",
              "      <td>0.157361</td>\n",
              "      <td>0.131396</td>\n",
              "      <td>0.083149</td>\n",
              "      <td>0.109792</td>\n",
              "      <td>...</td>\n",
              "      <td>0.126843</td>\n",
              "      <td>0.189541</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.328968</td>\n",
              "      <td>0.162218</td>\n",
              "      <td>0.120425</td>\n",
              "      <td>0.280409</td>\n",
              "      <td>0.189488</td>\n",
              "      <td>0.130992</td>\n",
              "      <td>0.067329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>0.058654</td>\n",
              "      <td>0.097302</td>\n",
              "      <td>0.068796</td>\n",
              "      <td>0.097973</td>\n",
              "      <td>0.067254</td>\n",
              "      <td>0.086970</td>\n",
              "      <td>0.122457</td>\n",
              "      <td>0.098479</td>\n",
              "      <td>0.066961</td>\n",
              "      <td>0.083599</td>\n",
              "      <td>...</td>\n",
              "      <td>0.091766</td>\n",
              "      <td>0.120511</td>\n",
              "      <td>0.328968</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108908</td>\n",
              "      <td>0.088921</td>\n",
              "      <td>0.618468</td>\n",
              "      <td>0.130787</td>\n",
              "      <td>0.098220</td>\n",
              "      <td>0.056897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>0.075098</td>\n",
              "      <td>0.082217</td>\n",
              "      <td>0.107523</td>\n",
              "      <td>0.109166</td>\n",
              "      <td>0.115331</td>\n",
              "      <td>0.133413</td>\n",
              "      <td>0.135411</td>\n",
              "      <td>0.175335</td>\n",
              "      <td>0.139938</td>\n",
              "      <td>0.198333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.368000</td>\n",
              "      <td>0.543167</td>\n",
              "      <td>0.162218</td>\n",
              "      <td>0.108908</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.418550</td>\n",
              "      <td>0.107466</td>\n",
              "      <td>0.251363</td>\n",
              "      <td>0.257507</td>\n",
              "      <td>0.107236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>0.068696</td>\n",
              "      <td>0.069394</td>\n",
              "      <td>0.096458</td>\n",
              "      <td>0.089090</td>\n",
              "      <td>0.106098</td>\n",
              "      <td>0.109384</td>\n",
              "      <td>0.103990</td>\n",
              "      <td>0.133346</td>\n",
              "      <td>0.138718</td>\n",
              "      <td>0.165686</td>\n",
              "      <td>...</td>\n",
              "      <td>0.274047</td>\n",
              "      <td>0.240868</td>\n",
              "      <td>0.120425</td>\n",
              "      <td>0.088921</td>\n",
              "      <td>0.418550</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.089666</td>\n",
              "      <td>0.213903</td>\n",
              "      <td>0.323453</td>\n",
              "      <td>0.144101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>0.054583</td>\n",
              "      <td>0.084349</td>\n",
              "      <td>0.064189</td>\n",
              "      <td>0.086394</td>\n",
              "      <td>0.063360</td>\n",
              "      <td>0.079381</td>\n",
              "      <td>0.105806</td>\n",
              "      <td>0.089911</td>\n",
              "      <td>0.064239</td>\n",
              "      <td>0.078932</td>\n",
              "      <td>...</td>\n",
              "      <td>0.088265</td>\n",
              "      <td>0.114620</td>\n",
              "      <td>0.280409</td>\n",
              "      <td>0.618468</td>\n",
              "      <td>0.107466</td>\n",
              "      <td>0.089666</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141058</td>\n",
              "      <td>0.103476</td>\n",
              "      <td>0.058424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>0.059056</td>\n",
              "      <td>0.071076</td>\n",
              "      <td>0.076388</td>\n",
              "      <td>0.084737</td>\n",
              "      <td>0.079434</td>\n",
              "      <td>0.091725</td>\n",
              "      <td>0.103478</td>\n",
              "      <td>0.110489</td>\n",
              "      <td>0.090053</td>\n",
              "      <td>0.111642</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149370</td>\n",
              "      <td>0.201828</td>\n",
              "      <td>0.189488</td>\n",
              "      <td>0.130787</td>\n",
              "      <td>0.251363</td>\n",
              "      <td>0.213903</td>\n",
              "      <td>0.141058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.388382</td>\n",
              "      <td>0.099729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>0.058305</td>\n",
              "      <td>0.064031</td>\n",
              "      <td>0.076561</td>\n",
              "      <td>0.077548</td>\n",
              "      <td>0.081462</td>\n",
              "      <td>0.087882</td>\n",
              "      <td>0.091317</td>\n",
              "      <td>0.104375</td>\n",
              "      <td>0.097515</td>\n",
              "      <td>0.114614</td>\n",
              "      <td>...</td>\n",
              "      <td>0.159146</td>\n",
              "      <td>0.180192</td>\n",
              "      <td>0.130992</td>\n",
              "      <td>0.098220</td>\n",
              "      <td>0.257507</td>\n",
              "      <td>0.323453</td>\n",
              "      <td>0.103476</td>\n",
              "      <td>0.388382</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.134183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>0.050814</td>\n",
              "      <td>0.047170</td>\n",
              "      <td>0.064459</td>\n",
              "      <td>0.056153</td>\n",
              "      <td>0.070607</td>\n",
              "      <td>0.065522</td>\n",
              "      <td>0.060882</td>\n",
              "      <td>0.071900</td>\n",
              "      <td>0.089265</td>\n",
              "      <td>0.085327</td>\n",
              "      <td>...</td>\n",
              "      <td>0.101223</td>\n",
              "      <td>0.090280</td>\n",
              "      <td>0.067329</td>\n",
              "      <td>0.056897</td>\n",
              "      <td>0.107236</td>\n",
              "      <td>0.144101</td>\n",
              "      <td>0.058424</td>\n",
              "      <td>0.099729</td>\n",
              "      <td>0.134183</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24 rows Ã— 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a07d21a1-821d-47d6-8ce2-c74177714848')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a07d21a1-821d-47d6-8ce2-c74177714848 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a07d21a1-821d-47d6-8ce2-c74177714848');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Creating adjacency matrix\n",
        "\n",
        "data_adj= pd.read_csv('/content/distanceNodes.txt', encoding='utf8', delimiter='\\t')\n",
        "\n",
        "#create new column calling Distance_KM, which calculates distance between nodes in km\n",
        "data_adj['Distance_KM']=data_adj['NEAR_DIST']/1000\n",
        "\n",
        "#  Change the nodes id\n",
        "replacement_mapping_dict = {\n",
        "    0: 141, 1: 143, 2: 195, 3: 181, 4: 5, 5: 88, 6: 138, 7: 254, 8: 142, 9: 113, 10: 192, 11: 243, 12: 78, 13: 92, \n",
        "    14: 177, 15: 126, 16: 228, 17: 47, 18: 220, 19: 72, 20: 281, 21: 323, 22:217, 23:296\n",
        "}\n",
        "data_fin = data_adj[[\"IN_FID\", \"NEAR_FID\"]].replace(replacement_mapping_dict)\n",
        "\n",
        "# Replace columns with the new created columns\n",
        "data_adj['IN_FID'] = data_fin[\"IN_FID\"]\n",
        "data_adj['NEAR_FID'] = data_fin[\"NEAR_FID\"]\n",
        "\n",
        "### create Adjacency matrix and replace column and index names according to grid cells id where air quality stations are located\n",
        "\n",
        "am = pd.DataFrame(np.zeros(shape=(24, 24)))\n",
        "am.rename(columns=replacement_mapping_dict, index =replacement_mapping_dict, inplace=True)\n",
        "adj_mat = am.sort_index(axis=1)\n",
        "adj_mat_complete = adj_mat.sort_index()\n",
        "\n",
        "\n",
        "### Adjacency matrix\n",
        "\n",
        "for i in data_adj.IN_FID.unique():\n",
        "  for j in data_adj.NEAR_FID.unique():\n",
        "    if i==j:\n",
        "      adj_mat_complete.at[i,j]=0\n",
        "    else:      \n",
        "      adj_mat_complete.at[i,j]=1/data_adj.loc[(data_adj['IN_FID'] == i) & (data_adj['NEAR_FID'] == j)]['Distance_KM']\n",
        "   \n",
        "      \n",
        "adj_mat_complete  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vUWMs4WCl1c",
        "outputId": "6bd07039-affe-4f59-edeb-7377ea8cce6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4367, 24, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# To open the file containing nodes features\n",
        "\n",
        "data = pd.read_csv('/content/Madrid_Stations_2019.csv', header=None)\n",
        "data_test = pd.read_csv('/content/Madrid_Stations_2020.csv', header=None)\n",
        "fin_data=data.to_numpy().reshape(-1, 24, 20)\n",
        "fin_data_test=data_test.to_numpy().reshape(-1, 24, 20)\n",
        "fin_data_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZnJlHH11Y5x"
      },
      "outputs": [],
      "source": [
        "# select columns for further analysis, including 'NO2', 'intensidad', 'ocupacion', 'windSpeed', ' Pressure', ' SolarRad',' Temperature', ' Humidity', 'carga', 'vmed', \n",
        "# 'windDir_Categ_east', 'windDir_Categ_north', 'windDir_Categ_northeast', 'windDir_Categ_northwest', 'windDir_Categ_south',\n",
        "#     'windDir_Categ_southeast', 'windDir_Categ_southwest', 'windDir_Categ_west'\n",
        "\n",
        "fin_data_test = fin_data_test[:, :,np.r_[0:10, 12:20]]\n",
        "fin_data = fin_data[:, :,np.r_[0:10, 12:20]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCB5u6Ei1V46"
      },
      "outputs": [],
      "source": [
        "# standardise train data\n",
        "\n",
        "data = fin_data.transpose(\n",
        "            (1, 2, 0)\n",
        "        )\n",
        "data = data.astype(np.float32)\n",
        "\n",
        "\n",
        "# standardise (via Z-Score Method)\n",
        "means = np.mean(data, axis=(0, 2))\n",
        "data_norm= data- means.reshape(1, -1, 1)\n",
        "stds = np.std(data_norm, axis=(0, 2))\n",
        "data_norm= data_norm/ stds.reshape(1, -1, 1)\n",
        "fin_data_norm = data_norm.transpose(2, 0, 1)\n",
        "fin_data = data.transpose(2, 0, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RaX5h41QUvk",
        "outputId": "a5e8eb8c-473d-4db7-bc1f-50890bbf59cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4344, 24, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "fin_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XblUgo_GTldw"
      },
      "outputs": [],
      "source": [
        "# standardise test data\n",
        "\n",
        "data = fin_data_test.transpose(\n",
        "            (1, 2, 0)\n",
        "        )\n",
        "data = data.astype(np.float32)\n",
        "\n",
        "data_norm= data- means.reshape(1, -1, 1)\n",
        "data_norm= data_norm/ stds.reshape(1, -1, 1)\n",
        "fin_data_test = data.transpose(2, 0, 1)\n",
        "fin_data_test_norm = data_norm.transpose(2, 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-GPFJVGTdia",
        "outputId": "bd60ed72-dc87-46b4-fb06-29e4d4881945"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4367, 24, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "fin_data_test_norm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyrT376CXEE1"
      },
      "outputs": [],
      "source": [
        "# split dataset to X and y (dependent and independent)\n",
        "\n",
        "def split_sequence(sequence, seq_notNorm, time_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "   \n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i +12\n",
        "\t\ttime_steps_starter = 0  # it can be assigned as one of the following {0, 12, 24, 36}\n",
        "\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix+time_steps_starter+time_steps > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern    \n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], seq_notNorm[end_ix+time_steps_starter:end_ix+time_steps_starter+time_steps]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "    \n",
        "\treturn np.array(X), np.array(y)\n",
        " \n",
        "\n",
        "# choose a number of time steps \n",
        "time_steps = 12\n",
        "X_train, y_train = split_sequence(fin_data_norm, fin_data, time_steps)\n",
        "X_test, y_test = split_sequence(fin_data_test_norm, fin_data_test, time_steps)\n",
        "\n",
        "# to select only nitrogen dioxide as a target feature\n",
        "y_train = y_train[:, :, :, 0]\n",
        "y_test = y_test[:, :, :, 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TijYCg8j3_49",
        "outputId": "60fc4a15-49a9-4398-ef06-29ddc1e7cd3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4343, 12, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9sVQ3kJXpS9",
        "outputId": "d48069d2-aa9b-4b66-a3a1-a07f6195d92c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4320, 12, 24, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SbxlFQ2JsAf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the models and run them (A3T-GCN, LSTM and GRU)\n",
        "\n",
        "LSTM"
      ],
      "metadata": {
        "id": "2Rny1xvRsDWh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te68AEaDjgf2"
      },
      "outputs": [],
      "source": [
        "# LSTM\n",
        "# reshape the data for LSTM input\n",
        "\n",
        "number_selected_columns =18\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 24*number_selected_columns))\n",
        "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 24*number_selected_columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVf6syYcafEb"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(432,input_shape=(X_train.shape[1], 24*number_selected_columns)))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(LSTM(1024, return_sequences=True))\n",
        "model.add(LSTM(512, return_sequences=True))\n",
        "model.add(Dense(24))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXuHvfdJbKdj"
      },
      "outputs": [],
      "source": [
        "# run LSTM\n",
        "\n",
        "lstm_model = model.fit(X_train_reshaped, y_train, epochs=100, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzu0SlJezwvO",
        "outputId": "c8e2f5b7-4a5a-402c-d268-42208d80c523"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4307, 12, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVnMeW5YbcOz"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(X_test_reshaped, verbose=1)\n",
        "yhat_reshaped = yhat.reshape(-1,24)\n",
        "y_test_reshaped=  y_test.reshape(-1,24)\n",
        "rmse = mean_squared_error(yhat_reshaped, y_test_reshaped, squared=False)\n",
        "mae = mean_absolute_error(yhat_reshaped, y_test_reshaped)\n",
        "print('Test Score: %.2f RMSE' % (rmse))\n",
        "print('Test Score: %.2f MAE' % (mae))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.stats.pearsonr(yhat_reshaped.reshape(-1), y_test_reshaped.reshape(-1))"
      ],
      "metadata": {
        "id": "D8GFbARs-5mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0vp-WEvVuB1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU"
      ],
      "metadata": {
        "id": "ZIylBL5Dujrm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8_9VpbSutmO"
      },
      "outputs": [],
      "source": [
        "# GRU\n",
        "# reshape the data for GRU input\n",
        "\n",
        "number_selected_columns =18\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 24*number_selected_columns))\n",
        "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 24*number_selected_columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A_lSpItuvuf"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(432,input_shape=(X_train.shape[1], 24*number_selected_columns)))\n",
        "model.add(GRU(512, return_sequences=True))\n",
        "model.add(GRU(1024, return_sequences=True))\n",
        "model.add(GRU(512, return_sequences=True))\n",
        "model.add(Dense(24))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1_ZirvzuxTG"
      },
      "outputs": [],
      "source": [
        "# run GRU\n",
        "\n",
        "gru_model = model.fit(X_train_reshaped, y_train, epochs=100, verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18O8U211uz-O"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(X_test_reshaped, verbose=1)\n",
        "yhat_reshaped = yhat.reshape(-1,24)\n",
        "y_test_reshaped=  y_test.reshape(-1,24)\n",
        "rmse = mean_squared_error(yhat_reshaped, y_test_reshaped, squared=False)\n",
        "mae = mean_absolute_error(yhat_reshaped, y_test_reshaped)\n",
        "print('Test Score: %.2f RMSE' % (rmse))\n",
        "print('Test Score: %.2f MAE' % (mae))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.stats.pearsonr(yhat_reshaped.reshape(-1), y_test_reshaped.reshape(-1))"
      ],
      "metadata": {
        "id": "JTCzNkMb-37H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XxqXggg9uhC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A3T-GCN"
      ],
      "metadata": {
        "id": "qp_C1GBUuHXx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6ZxltmCXZMp"
      },
      "outputs": [],
      "source": [
        "#to convert adjacency dataframe to numpy\n",
        "adj = adj_mat_complete.to_numpy()\n",
        "\n",
        "#transpose train data\n",
        "data = fin_data.transpose(\n",
        "            (1, 2, 0)\n",
        "        )\n",
        "data = data.astype(np.float32)\n",
        "\n",
        "\n",
        "# standardise (via Z-Score Method)\n",
        "means = np.mean(data, axis=(0, 2))\n",
        "data_norm= data- means.reshape(1, -1, 1)\n",
        "stds = np.std(data_norm, axis=(0, 2))\n",
        "data_norm= data_norm/ stds.reshape(1, -1, 1)\n",
        "\n",
        "#to convert adjacency matrix and data totorch\n",
        "adj = torch.from_numpy(adj)\n",
        "data_norm= torch.from_numpy(data_norm)\n",
        "data= torch.from_numpy(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqT1mwmThbPN"
      },
      "outputs": [],
      "source": [
        "#transpose test data\n",
        "data_test = fin_data_test.transpose(\n",
        "            (1, 2, 0)\n",
        "        )\n",
        "data_test = data_test.astype(np.float32)\n",
        "\n",
        "\n",
        "# Normalise as in DCRNN paper (via Z-Score Method)\n",
        "\n",
        "data_test_norm= data_test - means.reshape(1, -1, 1)\n",
        "data_test_norm = data_test_norm/ stds.reshape(1, -1, 1)\n",
        "\n",
        "\n",
        "data_test= torch.from_numpy(data_test)\n",
        "data_test_norm = torch.from_numpy(data_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j9q2CEB-Om6",
        "outputId": "7b445d2a-cef1-4611-e39a-d92bd8d4aed9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([24, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "adj.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdK3LHqP-QaQ",
        "outputId": "c80e6a2b-6e6e-4df1-dcd8-0135b4bc1aed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([24, 18, 4367])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "data_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENE2S1bjgsYb"
      },
      "outputs": [],
      "source": [
        "#from adjacency matrix extract the edge indices and edge weights\n",
        "\n",
        "edge_indices, values = dense_to_sparse(adj)\n",
        "edge_indices = edge_indices.numpy()\n",
        "values = values.numpy()\n",
        "edges = edge_indices\n",
        "edge_weights = values\n",
        "batch =64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie4hIMlm-pcg",
        "outputId": "032aa5d4-c8df-4ec8-d276-f95a2c6a4ea6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 552)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "edges.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm83WCRV-rtQ",
        "outputId": "627af7e4-7885-40b1-ac21-2c995b4e0380"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(552,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "edge_weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibGbQjvdS0F6"
      },
      "outputs": [],
      "source": [
        "class MadridDatasetLoader(object):\n",
        "    \"\"\"The dataset is based on 24 stations (nodes) each having 20 features (nodal features) \n",
        "    and 276 edges connecting each pair of nodes, the edge weights are the distance between the edges.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, data_norm, edges, edge_weights, batch):\n",
        "        super(MadridDatasetLoader, self).__init__()\n",
        "        self.data = data\n",
        "        self.data_norm = data_norm\n",
        "        self.edges = edges \n",
        "        self.edge_weights= edge_weights\n",
        "        self.batch = batch\n",
        "\n",
        "\n",
        "    def _generate_task(self, num_timesteps_in: int = 6, num_timesteps_out: int = 6):\n",
        "        \"\"\"Uses the node features of the graph and generates a feature/target\n",
        "        relationship of the shape\n",
        "        (num_nodes, num_node_features, num_timesteps_in) -> (num_nodes, num_timesteps_out)\n",
        "        \n",
        "\n",
        "        Args:\n",
        "            num_timesteps_in (int): number of timesteps the sequence model sees\n",
        "            num_timesteps_out (int): number of timesteps the sequence model has to predict\n",
        "        \"\"\"\n",
        "        time_steps_starter =   12 # it can be assigned as one of the following {0, 12, 24, 36}\n",
        "        indices = [\n",
        "            (i, i +time_steps_starter+ (num_timesteps_in + num_timesteps_out))\n",
        "            for i in range(self.data.shape[2] - (time_steps_starter+num_timesteps_in + num_timesteps_out) + 1)\n",
        "        ]\n",
        "        print(indices)\n",
        "        # Generate observations\n",
        "        features, target = [], []\n",
        "        for i, j in indices:\n",
        "            features.append((self.data_norm[:, :, i : i + num_timesteps_in]).numpy())\n",
        "            target.append((self.data[  :, 0, i + num_timesteps_in +time_steps_starter: j]).numpy())\n",
        "\n",
        "        self.features = features\n",
        "        self.targets = target\n",
        "\n",
        "    def get_dataset(\n",
        "        self, num_timesteps_in: int = 6, num_timesteps_out: int = 6\n",
        "    ) -> StaticGraphTemporalSignal:\n",
        "        \"\"\"Returns data iterator for the dataset as an instance of the\n",
        "        static graph temporal signal class.\n",
        "\n",
        "        Return types:\n",
        "            * **dataset** *(StaticGraphTemporalSignal)* - The forecasting dataset.\n",
        "        \"\"\"\n",
        "        \n",
        "        self._generate_task(num_timesteps_in, num_timesteps_out)\n",
        "        dataset = StaticGraphTemporalSignalBatch(\n",
        "            self.edges, self.edge_weights, self.features, self.targets, self.batch\n",
        "        )\n",
        "\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCa7JCuY-syX"
      },
      "outputs": [],
      "source": [
        "loader = MadridDatasetLoader(data_test, data_test_norm, edges, edge_weights, batch)\n",
        "dataset_test = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
        "print(\"Dataset type:  \", dataset_test)\n",
        "print(\"Number of samples / sequences: \",  len(set(dataset_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQ2A9CVG-wn2"
      },
      "outputs": [],
      "source": [
        "loader = MadridDatasetLoader(data, data_norm, edges, edge_weights, batch)\n",
        "dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
        "print(\"Dataset type:  \", dataset)\n",
        "print(\"Number of samples / sequences: \",  len(set(dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSQER-GswxbR"
      },
      "outputs": [],
      "source": [
        "# define A3T-GCN\n",
        "\n",
        "unit_num  = 32  # This is number of units in order to construct the architecture of the A3T-GCN. It can be assigned as one of the following {32, 64, 128, 256}\n",
        "\n",
        "class TemporalGNN(torch.nn.Module):\n",
        "    def __init__(self, node_features, periods):\n",
        "        super(TemporalGNN, self).__init__()\n",
        "        # Attention Temporal Graph Convolutional Cell\n",
        "        self.tgnn = A3TGCN(in_channels=node_features, \n",
        "                           out_channels=unit_num, \n",
        "                           periods=periods)\n",
        "        # Equals single-shot prediction\n",
        "        self.linear = torch.nn.Linear(unit_num, periods)\n",
        "\n",
        "    def forward(self, x, edge_index,  edge_weight):\n",
        "        \"\"\"\n",
        "        x = Node features for T time steps\n",
        "        edge_index = Graph edge indices\n",
        "        \"\"\"\n",
        "        h = self.tgnn(x, edge_index,  edge_weight)\n",
        "        h = F.relu(h)\n",
        "        h = self.linear(h)\n",
        "        return h\n",
        "\n",
        "TemporalGNN(node_features=18, periods=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNSDo75_FHfT"
      },
      "outputs": [],
      "source": [
        "# GPU support\n",
        "device = torch.device('cpu') # cuda\n",
        "\n",
        "\n",
        "# Create model and optimizers\n",
        "model = TemporalGNN(node_features=18, periods=12).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "model.train()\n",
        "\n",
        "print(\"Running training...\")\n",
        "for epoch in range(100): \n",
        "    loss = 0\n",
        "    step = 0\n",
        "    for snapshot in dataset:\n",
        "        snapshot = snapshot.to(device)\n",
        "        # Get model predictions\n",
        "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "        # Mean Squared Error\n",
        "        loss = loss + torch.mean((y_hat-snapshot.y)**2) \n",
        "        step += 1\n",
        "        \n",
        "\n",
        "    loss = loss / (step + 1)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    print(\"Epoch {} train MSE: {:.4f}\".format(epoch, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNERp-_xs27y"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "loss = 0\n",
        "step = 0\n",
        "\n",
        "# Store for analysis\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "for snapshot in dataset_test:\n",
        "    snapshot = snapshot.to(device)\n",
        "    # Get predictions\n",
        "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "    # Mean Absolute Error\n",
        "    loss = loss + torch.mean(torch.abs(y_hat-snapshot.y))\n",
        "    # Store for analysis below\n",
        "    labels.append(snapshot.y)\n",
        "    predictions.append(y_hat)\n",
        "    step += 1\n",
        "  \n",
        "\n",
        "loss = loss / (step+1)\n",
        "loss = loss.item()\n",
        "print(\"Test MAE: {:.4f}\".format(loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZBeg07mZoXh"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "loss = 0\n",
        "step = 0\n",
        "\n",
        "# Store for analysis\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "for snapshot in dataset_test:\n",
        "    snapshot = snapshot.to(device)\n",
        "    # Get predictions\n",
        "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
        "\n",
        "    # Root Mean Squared Error\n",
        "    loss = loss + torch.sqrt(torch.mean((y_hat-snapshot.y)**2)) \n",
        "    # Store for analysis below\n",
        "    labels.append(snapshot.y)\n",
        "    predictions.append(y_hat)\n",
        "    step += 1\n",
        "\n",
        "loss = loss / (step+1)\n",
        "loss = loss.item()\n",
        "print(\"Test RMSE: {:.4f}\".format(loss))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nU0B0skW-9zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqmZM5qH_HgJ"
      },
      "outputs": [],
      "source": [
        "# it is calculated for all nodes\n",
        "\n",
        "ALLNode_pred = []\n",
        "AllNode_true = []\n",
        "for item in predictions:\n",
        "  for node in range(24):\n",
        "    for hour in range(12):\n",
        "      AllNode_pred.append(item[node][hour].detach().cpu().numpy().item(0))\n",
        "\n",
        "\n",
        "for item in labels:\n",
        "  for node in range(24):\n",
        "    for hour in range(12):\n",
        "      ALLNode_true.append(item[node][hour].detach().cpu().numpy().item(0))\n",
        "\n",
        "\n",
        "AllNode_pred_np = np.array(AllNode_pred)\n",
        "ALLNode_pred_np_resh = AllNode_pred_np.reshape(-1, 24, 12)\n",
        "AllNode_true_np = np.array(AllNode_true)\n",
        "AllNode_true_np_resh = AllNode_true_np.reshape(-1, 24, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdEd_JDhYMeO"
      },
      "outputs": [],
      "source": [
        "\n",
        "scipy.stats.pearsonr(AllNode_pred_np, AllNode_true_np)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "GNN_NO2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
